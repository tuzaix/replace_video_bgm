#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘BGMåˆ†ç¦»å’Œæ›¿æ¢å·¥å…· v3.0

æ”¹è¿›ç‰ˆæœ¬ï¼Œå‚è€ƒvideo_separatorå®ç°æ¨¡å¼ï¼š
1. å¢å¼ºçš„éŸ³é¢‘åˆ†ç¦»ç®—æ³•ï¼Œæ”¯æŒå¤šç§åˆ†ç¦»ç­–ç•¥
2. åˆ†ç¦»è´¨é‡æ§åˆ¶å’Œè¯„ä¼°åŠŸèƒ½
3. éŸ³é¢‘é¢„å¤„ç†åŠŸèƒ½ï¼ˆé™å™ªã€æ ‡å‡†åŒ–ç­‰ï¼‰
4. å¯é…ç½®çš„åˆ†ç¦»å‚æ•°
5. å¤šæ¨¡å‹æ”¯æŒå’Œè‡ªåŠ¨é€‰æ‹©

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 3.0.0
"""

import os
import sys
import gc
import random
import logging
import argparse
import subprocess
import threading
import signal
import atexit
import numpy as np
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Tuple, Optional, Dict, Any
import time
from dataclasses import dataclass
from enum import Enum

try:
    import torch
    import torchaudio
    import librosa
    import soundfile as sf
    from demucs.pretrained import get_model
    from demucs.apply import apply_model
    import moviepy.editor as mp
    from moviepy.video.io.VideoFileClip import VideoFileClip
    from moviepy.audio.io.AudioFileClip import AudioFileClip
    from scipy import signal
    from scipy.signal import butter, filtfilt
    # å¯¼å…¥video_separatoræ¨¡å—ç”¨äºæ‰¹é‡åˆ†ç¦»
    from video_separator import VideoSeparator
    from config import get_config, SUPPORTED_FORMATS
except ImportError as e:
    print(f"ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“: {e}")
    print("è¯·è¿è¡Œ: pip install -r requirements.txt")
    sys.exit(1)


class SeparationStrategy(Enum):
    """éŸ³é¢‘åˆ†ç¦»ç­–ç•¥æšä¸¾"""
    VOCALS_ONLY = "vocals_only"           # åªä¿ç•™äººå£°
    VOCALS_AND_OTHER = "vocals_and_other" # ä¿ç•™äººå£°å’Œå…¶ä»–éŸ³é¢‘
    CUSTOM_MIX = "custom_mix"             # è‡ªå®šä¹‰æ··åˆæ¯”ä¾‹
    ADAPTIVE = "adaptive"                 # è‡ªé€‚åº”ç­–ç•¥


@dataclass
class SeparationConfig:
    """éŸ³é¢‘åˆ†ç¦»é…ç½®"""
    strategy: SeparationStrategy = SeparationStrategy.VOCALS_ONLY  # é»˜è®¤ä»…ä¿ç•™äººå£°
    model_name: str = "htdemucs"
    overlap: float = 0.25
    split: bool = True
    vocals_volume: float = 2         # äººå£°éŸ³é‡å¢å¼º30%ï¼Œç¡®ä¿æ¸…æ™°çªå‡º
    drums_volume: float = 0.0           # é¼“å£°é»˜è®¤ä¸ä¿ç•™
    bass_volume: float = 0.0            # ä½éŸ³é»˜è®¤ä¸ä¿ç•™
    other_volume: float = 0.2           # å…¶ä»–éŸ³é¢‘ï¼ˆç¯å¢ƒéŸ³ç­‰ï¼‰é€‚ä¸­ä¿ç•™ï¼Œä¸æ–°BGMå¹³è¡¡
    enable_preprocessing: bool = True
    enable_quality_check: bool = True
    quality_threshold: float = 0.7
    # æ–°å¢ï¼šæ‰¹é‡åˆ†ç¦»é…ç½®
    use_batch_separation: bool = False  # æ˜¯å¦ä½¿ç”¨video_separatorçš„æ‰¹é‡åˆ†ç¦»åŠŸèƒ½
    batch_max_workers: int = 2          # æ‰¹é‡åˆ†ç¦»çš„æœ€å¤§å¹¶å‘æ•°


@dataclass
class AudioQualityMetrics:
    """éŸ³é¢‘è´¨é‡è¯„ä¼°æŒ‡æ ‡"""
    snr: float = 0.0          # ä¿¡å™ªæ¯”
    spectral_centroid: float = 0.0  # é¢‘è°±è´¨å¿ƒ
    zero_crossing_rate: float = 0.0  # è¿‡é›¶ç‡
    rms_energy: float = 0.0   # RMSèƒ½é‡
    quality_score: float = 0.0  # ç»¼åˆè´¨é‡åˆ†æ•°


class AudioPreprocessor:
    """éŸ³é¢‘é¢„å¤„ç†å™¨"""
    
    def __init__(self, sample_rate: int = 44100):
        """
        åˆå§‹åŒ–éŸ³é¢‘é¢„å¤„ç†å™¨
        
        Args:
            sample_rate: é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
    
    def normalize_audio(self, audio: np.ndarray) -> np.ndarray:
        """
        éŸ³é¢‘æ ‡å‡†åŒ–
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘æ•°ç»„
            
        Returns:
            æ ‡å‡†åŒ–åçš„éŸ³é¢‘
        """
        # é˜²æ­¢é™¤é›¶
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            return audio / max_val * 0.95
        return audio
    
    def apply_highpass_filter(self, audio: np.ndarray, cutoff: float = 80.0) -> np.ndarray:
        """
        åº”ç”¨é«˜é€šæ»¤æ³¢å™¨å»é™¤ä½é¢‘å™ªå£°
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            cutoff: æˆªæ­¢é¢‘ç‡
            
        Returns:
            æ»¤æ³¢åçš„éŸ³é¢‘
        """
        nyquist = self.sample_rate * 0.5
        normal_cutoff = cutoff / nyquist
        b, a = butter(5, normal_cutoff, btype='high', analog=False)
        return filtfilt(b, a, audio)
    
    def reduce_noise(self, audio: np.ndarray, noise_factor: float = 0.1) -> np.ndarray:
        """
        ç®€å•çš„å™ªå£°æŠ‘åˆ¶
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            noise_factor: å™ªå£°æŠ‘åˆ¶å› å­
            
        Returns:
            é™å™ªåçš„éŸ³é¢‘
        """
        # è®¡ç®—éŸ³é¢‘çš„RMS
        rms = np.sqrt(np.mean(audio**2))
        
        # å¦‚æœRMSå¤ªå°ï¼Œè®¤ä¸ºæ˜¯å™ªå£°
        threshold = rms * noise_factor
        mask = np.abs(audio) > threshold
        
        # åº”ç”¨è½¯é˜ˆå€¼
        return audio * mask + audio * (1 - mask) * 0.1
    
    def preprocess(self, audio: np.ndarray) -> np.ndarray:
        """
        å®Œæ•´çš„éŸ³é¢‘é¢„å¤„ç†æµç¨‹
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            
        Returns:
            é¢„å¤„ç†åçš„éŸ³é¢‘
        """
        # æ ‡å‡†åŒ–
        audio = self.normalize_audio(audio)
        
        # é«˜é€šæ»¤æ³¢
        audio = self.apply_highpass_filter(audio)
        
        # é™å™ª
        audio = self.reduce_noise(audio)
        
        return audio


class AudioQualityAnalyzer:
    """éŸ³é¢‘è´¨é‡åˆ†æå™¨"""
    
    def __init__(self, sample_rate: int = 44100):
        """
        åˆå§‹åŒ–éŸ³é¢‘è´¨é‡åˆ†æå™¨
        
        Args:
            sample_rate: é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
    
    def calculate_snr(self, signal_audio: np.ndarray, noise_audio: np.ndarray) -> float:
        """
        è®¡ç®—ä¿¡å™ªæ¯”
        
        Args:
            signal_audio: ä¿¡å·éŸ³é¢‘
            noise_audio: å™ªå£°éŸ³é¢‘
            
        Returns:
            ä¿¡å™ªæ¯” (dB)
        """
        signal_power = np.mean(signal_audio**2)
        noise_power = np.mean(noise_audio**2)
        
        if noise_power == 0:
            return float('inf')
        
        snr = 10 * np.log10(signal_power / noise_power)
        return snr
    
    def calculate_spectral_centroid(self, audio: np.ndarray) -> float:
        """
        è®¡ç®—é¢‘è°±è´¨å¿ƒ
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            
        Returns:
            é¢‘è°±è´¨å¿ƒ
        """
        centroid = librosa.feature.spectral_centroid(y=audio, sr=self.sample_rate)[0]
        return np.mean(centroid)
    
    def calculate_zero_crossing_rate(self, audio: np.ndarray) -> float:
        """
        è®¡ç®—è¿‡é›¶ç‡
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            
        Returns:
            è¿‡é›¶ç‡
        """
        zcr = librosa.feature.zero_crossing_rate(audio)[0]
        return np.mean(zcr)
    
    def calculate_rms_energy(self, audio: np.ndarray) -> float:
        """
        è®¡ç®—RMSèƒ½é‡
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            
        Returns:
            RMSèƒ½é‡
        """
        rms = librosa.feature.rms(y=audio)[0]
        return np.mean(rms)
    
    def analyze_quality(self, audio: np.ndarray, original_audio: np.ndarray = None) -> AudioQualityMetrics:
        """
        åˆ†æéŸ³é¢‘è´¨é‡
        
        Args:
            audio: å¾…åˆ†æéŸ³é¢‘
            original_audio: åŸå§‹éŸ³é¢‘ï¼ˆç”¨äºè®¡ç®—SNRï¼‰
            
        Returns:
            éŸ³é¢‘è´¨é‡æŒ‡æ ‡
        """
        metrics = AudioQualityMetrics()
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        metrics.spectral_centroid = self.calculate_spectral_centroid(audio)
        metrics.zero_crossing_rate = self.calculate_zero_crossing_rate(audio)
        metrics.rms_energy = self.calculate_rms_energy(audio)
        
        if original_audio is not None:
            # è®¡ç®—æ®‹å·®ä½œä¸ºå™ªå£°
            residual = original_audio - audio
            metrics.snr = self.calculate_snr(audio, residual)
        
        # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•° (0-1)
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„è¯„åˆ†ç®—æ³•ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
        centroid_score = min(metrics.spectral_centroid / 2000, 1.0)  # æ ‡å‡†åŒ–åˆ°0-1
        zcr_score = 1.0 - min(metrics.zero_crossing_rate * 10, 1.0)  # è¿‡é›¶ç‡è¶Šä½è¶Šå¥½
        rms_score = min(metrics.rms_energy * 10, 1.0)  # RMSèƒ½é‡
        
        metrics.quality_score = (centroid_score + zcr_score + rms_score) / 3
        
        return metrics


class AdvancedAudioSeparator:
    """é«˜çº§éŸ³é¢‘åˆ†ç¦»å™¨"""
    
    def __init__(self, config: SeparationConfig, device: str = 'cpu'):
        """
        åˆå§‹åŒ–é«˜çº§éŸ³é¢‘åˆ†ç¦»å™¨
        
        Args:
            config: åˆ†ç¦»é…ç½®
            device: è®¡ç®—è®¾å¤‡
        """
        self.config = config
        self.device = device
        self.model = None
        self.preprocessor = AudioPreprocessor()
        self.quality_analyzer = AudioQualityAnalyzer()
        self.logger = logging.getLogger(__name__)
        
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½demucsæ¨¡å‹"""
        try:
            self.model = get_model(self.config.model_name)
            self.model.to(self.device)
            self.model.eval()
            self.logger.info(f"å·²åŠ è½½æ¨¡å‹: {self.config.model_name}")
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _apply_separation_strategy(self, sources: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨åˆ†ç¦»ç­–ç•¥
        
        Args:
            sources: demucsåˆ†ç¦»çš„éŸ³é¢‘æº [vocals, drums, bass, other]
            
        Returns:
            å¤„ç†åçš„éŸ³é¢‘
        """
        vocals, drums, bass, other = sources[0], sources[1], sources[2], sources[3]
        
        if self.config.strategy == SeparationStrategy.VOCALS_ONLY:
            # åªä¿ç•™äººå£°ï¼Œå®Œå…¨å»é™¤èƒŒæ™¯éŸ³ä¹
            return vocals * self.config.vocals_volume
        
        elif self.config.strategy == SeparationStrategy.VOCALS_AND_OTHER:
            # ä¿ç•™äººå£°å’Œç¯å¢ƒéŸ³ï¼Œå»é™¤åŸBGMï¼ˆæœ€ä½³é»˜è®¤ç­–ç•¥ï¼‰
            # è¿™æ˜¯æœ€ç¬¦åˆBGMæ›¿æ¢éœ€æ±‚çš„ç­–ç•¥ï¼š
            # - å®Œå…¨ä¿ç•™äººå£°å¯¹è¯/æ­Œå”±
            # - ä¿ç•™ç¯å¢ƒéŸ³æ•ˆï¼ˆè„šæ­¥å£°ã€é£å£°ã€æœºæ¢°å£°ç­‰ï¼‰
            # - å»é™¤åŸå§‹èƒŒæ™¯éŸ³ä¹ï¼Œä¸ºæ–°BGMè®©è·¯
            # - ä¸æ–°BGMæ··åˆåæ•ˆæœæœ€è‡ªç„¶
            self.logger.debug(f"åº”ç”¨VOCALS_AND_OTHERç­–ç•¥: äººå£°éŸ³é‡={self.config.vocals_volume}, ç¯å¢ƒéŸ³éŸ³é‡={self.config.other_volume}")
            return (vocals * self.config.vocals_volume + 
                   other * self.config.other_volume)
        
        elif self.config.strategy == SeparationStrategy.CUSTOM_MIX:
            # è‡ªå®šä¹‰æ··åˆæ¯”ä¾‹ï¼Œå®Œå…¨å¯æ§
            return (vocals * self.config.vocals_volume +
                   drums * self.config.drums_volume +
                   bass * self.config.bass_volume +
                   other * self.config.other_volume)
        
        elif self.config.strategy == SeparationStrategy.ADAPTIVE:
            # è‡ªé€‚åº”ç­–ç•¥ï¼šæ ¹æ®éŸ³é¢‘ç‰¹å¾åŠ¨æ€è°ƒæ•´
            return self._adaptive_mix(vocals, drums, bass, other)
        
        else:
            # é»˜è®¤ç­–ç•¥ï¼šä¿ç•™äººå£°å’Œé€‚é‡ç¯å¢ƒéŸ³
            self.logger.warning("ä½¿ç”¨é»˜è®¤åˆ†ç¦»ç­–ç•¥")
            return vocals * 1.0 + other * 0.4
    
    def _adaptive_mix(self, vocals: torch.Tensor, drums: torch.Tensor, 
                     bass: torch.Tensor, other: torch.Tensor) -> torch.Tensor:
        """
        è‡ªé€‚åº”æ··åˆç­–ç•¥ - æ™ºèƒ½åˆ†æéŸ³é¢‘ç‰¹å¾å¹¶ä¼˜åŒ–æ··åˆæ¯”ä¾‹
        
        Args:
            vocals, drums, bass, other: åˆ†ç¦»çš„éŸ³é¢‘æº
            
        Returns:
            è‡ªé€‚åº”æ··åˆåçš„éŸ³é¢‘
        """
        # è®¡ç®—å„ä¸ªæºçš„èƒ½é‡
        vocals_energy = torch.mean(vocals**2)
        drums_energy = torch.mean(drums**2)
        bass_energy = torch.mean(bass**2)
        other_energy = torch.mean(other**2)
        
        total_energy = vocals_energy + drums_energy + bass_energy + other_energy
        
        if total_energy == 0:
            return vocals
        
        # æ ¹æ®èƒ½é‡æ¯”ä¾‹è°ƒæ•´æ··åˆæƒé‡
        vocals_ratio = vocals_energy / total_energy
        other_ratio = other_energy / total_energy
        
        self.logger.debug(f"è‡ªé€‚åº”æ··åˆåˆ†æ: äººå£°æ¯”ä¾‹={vocals_ratio:.3f}, å…¶ä»–æ¯”ä¾‹={other_ratio:.3f}")
        
        # ä¼˜åŒ–çš„è‡ªé€‚åº”ç­–ç•¥ï¼šæ›´å¥½åœ°ä¿ç•™äººå£°ï¼Œé€‚åº¦ä¿ç•™ç¯å¢ƒéŸ³
        if vocals_ratio > 0.6:  # äººå£°å ä¸»å¯¼
            other_volume = 0.2
            self.logger.debug("æ£€æµ‹åˆ°äººå£°ä¸»å¯¼ï¼Œé™ä½ç¯å¢ƒéŸ³")
        elif vocals_ratio > 0.3:  # äººå£°ä¸­ç­‰
            other_volume = 0.3
            self.logger.debug("æ£€æµ‹åˆ°äººå£°ä¸­ç­‰ï¼Œä¿æŒé€‚ä¸­ç¯å¢ƒéŸ³")
        else:  # äººå£°è¾ƒå°‘
            other_volume = 0.5
            self.logger.debug("æ£€æµ‹åˆ°äººå£°è¾ƒå°‘ï¼Œä¿ç•™æ›´å¤šç¯å¢ƒéŸ³")
            
        return vocals * 1.0 + other * other_volume
    
    def _optimize_vocal_separation(self, separated_audio: torch.Tensor) -> torch.Tensor:
        """
        ä¼˜åŒ–äººå£°åˆ†ç¦»æ•ˆæœ
        
        Args:
            separated_audio: åˆ†ç¦»åçš„éŸ³é¢‘
            
        Returns:
            ä¼˜åŒ–åçš„éŸ³é¢‘
        """
        # åº”ç”¨è½»å¾®çš„é«˜é€šæ»¤æ³¢ï¼Œå¢å¼ºäººå£°æ¸…æ™°åº¦
        if separated_audio.dim() == 2:
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œå¤„ç†
            audio_np = separated_audio.cpu().numpy()
            
            # ç®€å•çš„é«˜é€šæ»¤æ³¢ï¼ˆå»é™¤ä½é¢‘å™ªéŸ³ï¼‰
            try:
                # è®¾è®¡é«˜é€šæ»¤æ³¢å™¨ï¼ˆæˆªæ­¢é¢‘ç‡80Hzï¼Œé€‚åˆå»é™¤ä½é¢‘å™ªéŸ³ä½†ä¿ç•™äººå£°ï¼‰
                sos = signal.butter(2, 80, btype='high', fs=44100, output='sos')
                filtered_audio = signal.sosfilt(sos, audio_np, axis=1)
                
                # è½¬æ¢å›tensor
                optimized_audio = torch.from_numpy(filtered_audio).to(separated_audio.device)
                self.logger.debug("åº”ç”¨é«˜é€šæ»¤æ³¢ä¼˜åŒ–äººå£°")
                return optimized_audio
            except Exception as e:
                self.logger.warning(f"éŸ³é¢‘ä¼˜åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹éŸ³é¢‘: {e}")
                return separated_audio
        
        return separated_audio
    
    def separate_audio(self, audio_path: Path, tmp_dir: Path) -> Tuple[Optional[Path], Optional[AudioQualityMetrics]]:
        """
        åˆ†ç¦»éŸ³é¢‘
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            tmp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•
            
        Returns:
            (åˆ†ç¦»åçš„éŸ³é¢‘è·¯å¾„, è´¨é‡æŒ‡æ ‡)
        """
        try:
            # ç¡®ä¿audio_pathæ˜¯Pathå¯¹è±¡
            if isinstance(audio_path, str):
                audio_path = Path(audio_path)
            
            self.logger.info(f"å¼€å§‹åˆ†ç¦»éŸ³é¢‘: {audio_path.name}")
            
            # åŠ è½½éŸ³é¢‘å¹¶ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
            try:
                waveform, sample_rate = torchaudio.load(str(audio_path))
                # å¼ºåˆ¶è½¬æ¢ä¸ºfloat32ç±»å‹ï¼Œé¿å…double/floatç±»å‹ä¸åŒ¹é…
                waveform = waveform.float()
                original_audio = waveform.clone()
                self.logger.debug(f"éŸ³é¢‘åŠ è½½æˆåŠŸï¼Œæ•°æ®ç±»å‹: {waveform.dtype}, å½¢çŠ¶: {waveform.shape}")
            except Exception as load_error:
                self.logger.error(f"éŸ³é¢‘åŠ è½½å¤±è´¥: {load_error}")
                return None, None
            
            # ç¡®ä¿éŸ³é¢‘ä¸ºç«‹ä½“å£°æ ¼å¼ï¼ˆdemucsè¦æ±‚2é€šé“è¾“å…¥ï¼‰
            if waveform.shape[0] == 1:
                # å•å£°é“è½¬ç«‹ä½“å£°ï¼šå¤åˆ¶é€šé“
                waveform = waveform.repeat(2, 1)
                self.logger.debug("å•å£°é“éŸ³é¢‘å·²è½¬æ¢ä¸ºç«‹ä½“å£°")
            elif waveform.shape[0] > 2:
                # å¤šé€šé“éŸ³é¢‘è½¬ç«‹ä½“å£°ï¼šå–å‰ä¸¤ä¸ªé€šé“
                waveform = waveform[:2, :]
                self.logger.debug("å¤šé€šé“éŸ³é¢‘å·²è½¬æ¢ä¸ºç«‹ä½“å£°")
            
            # é¢„å¤„ç†ï¼ˆä¿æŒç«‹ä½“å£°æ ¼å¼ï¼‰
            if self.config.enable_preprocessing:
                # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«è¿›è¡Œé¢„å¤„ç†
                processed_channels = []
                for channel_idx in range(waveform.shape[0]):
                    channel_audio = waveform[channel_idx].numpy()
                    processed_channel = self.preprocessor.preprocess(channel_audio)
                    processed_channels.append(processed_channel)
                
                # é‡æ–°ç»„åˆä¸ºç«‹ä½“å£°tensor
                processed_audio = np.stack(processed_channels, axis=0)
                waveform = torch.from_numpy(processed_audio).float()
            
            # ç¡®ä¿tensoråœ¨æ­£ç¡®è®¾å¤‡ä¸Šä¸”ä¸ºfloat32ç±»å‹
            waveform = waveform.to(self.device).float()
            
            # åº”ç”¨demucsæ¨¡å‹
            with torch.no_grad():
                # ç¡®ä¿è¾“å…¥tensorä¸ºfloat32ç±»å‹ï¼Œå¹¶æ·»åŠ batchç»´åº¦
                model_input = waveform.unsqueeze(0).float()
                self.logger.debug(f"æ¨¡å‹è¾“å…¥æ•°æ®ç±»å‹: {model_input.dtype}, å½¢çŠ¶: {model_input.shape}")
                
                # éªŒè¯è¾“å…¥å½¢çŠ¶ï¼šåº”è¯¥æ˜¯ [batch_size, channels, samples]
                if model_input.dim() != 3 or model_input.shape[1] != 2:
                    raise ValueError(f"æ¨¡å‹è¾“å…¥å½¢çŠ¶é”™è¯¯: {model_input.shape}, æœŸæœ›: [1, 2, samples]")
                
                sources = apply_model(
                    self.model, 
                    model_input,
                    device=self.device,
                    split=self.config.split,
                    overlap=self.config.overlap
                )[0]
            
            # åº”ç”¨åˆ†ç¦»ç­–ç•¥
            separated_audio = self._apply_separation_strategy(sources)
            
            # ä¼˜åŒ–äººå£°åˆ†ç¦»æ•ˆæœï¼ˆä»…å¯¹VOCALS_AND_OTHERå’ŒVOCALS_ONLYç­–ç•¥åº”ç”¨ï¼‰
            if self.config.strategy in [SeparationStrategy.VOCALS_AND_OTHER, SeparationStrategy.VOCALS_ONLY]:
                separated_audio = self._optimize_vocal_separation(separated_audio)
                self.logger.debug("åº”ç”¨äººå£°åˆ†ç¦»ä¼˜åŒ–")
            
            # ä¿å­˜åˆ†ç¦»åçš„éŸ³é¢‘åˆ°ä¸´æ—¶ç›®å½•
            output_path = tmp_dir / f"{audio_path.stem}_separated.wav"
            torchaudio.save(str(output_path), separated_audio.cpu(), sample_rate)
            
            # è´¨é‡è¯„ä¼°
            quality_metrics = None
            if self.config.enable_quality_check:
                separated_np = separated_audio.cpu().numpy()
                if separated_np.ndim > 1:
                    separated_np = np.mean(separated_np, axis=0)
                
                original_np = original_audio.numpy()
                if original_np.ndim > 1:
                    original_np = np.mean(original_np, axis=0)
                
                quality_metrics = self.quality_analyzer.analyze_quality(
                    separated_np, original_np
                )
                
                self.logger.info(f"åˆ†ç¦»è´¨é‡åˆ†æ•°: {quality_metrics.quality_score:.3f}")
                
                # å¦‚æœè´¨é‡ä¸è¾¾æ ‡ï¼Œè®°å½•è­¦å‘Š
                if quality_metrics.quality_score < self.config.quality_threshold:
                    self.logger.warning(f"åˆ†ç¦»è´¨é‡è¾ƒä½: {quality_metrics.quality_score:.3f}")
            
            # æ¸…ç†GPUå†…å­˜
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            self.logger.info(f"éŸ³é¢‘åˆ†ç¦»å®Œæˆ: {output_path.name}")
            return output_path, quality_metrics
            
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘åˆ†ç¦»å¤±è´¥ {audio_path.name}: {e}")
            return None, None


class VideoBGMReplacer:
    """è§†é¢‘BGMåˆ†ç¦»å’Œæ›¿æ¢å¤„ç†å™¨ v3.0"""
    
    def __init__(self, video_dir: str, bgm_dir: str, max_workers: int = 4, 
                 separation_config: Optional[SeparationConfig] = None):
        """
        åˆå§‹åŒ–BGMæ›¿æ¢å™¨
        
        Args:
            video_dir: è§†é¢‘æ–‡ä»¶ç›®å½•
            bgm_dir: BGMéŸ³é¢‘æ–‡ä»¶ç›®å½•
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            separation_config: åˆ†ç¦»é…ç½®
        """
        self.video_dir = Path(video_dir)
        self.bgm_dir = Path(bgm_dir)
        self.max_workers = max_workers
        self.separation_config = separation_config or SeparationConfig()
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.tmp_dir = self.video_dir / "tmp"
        self.output_dir = self.video_dir / "mixed_bgm_video"
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
        self.audio_extensions = {'.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a'}
        
        # æ£€æµ‹GPUæ”¯æŒ
        self.device = self._detect_device()
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆ›å»ºé«˜çº§éŸ³é¢‘åˆ†ç¦»å™¨
        self.audio_separator = AdvancedAudioSeparator(self.separation_config, self.device)
        
        # åˆ›å»ºvideo_separatorå®ä¾‹ï¼ˆç”¨äºæ‰¹é‡åˆ†ç¦»ï¼‰
        if self.separation_config.use_batch_separation:
            self.video_separator = VideoSeparator()
            self.logger.info("âœ… å·²å¯ç”¨æ‰¹é‡åˆ†ç¦»æ¨¡å¼")
        else:
            self.video_separator = None
            self.logger.info("âœ… ä½¿ç”¨ä¼ ç»Ÿåˆ†ç¦»æ¨¡å¼")
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self._create_directories()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_videos': 0,
            'successful': 0,
            'failed': 0,
            'avg_quality_score': 0.0
        }
    
    def _detect_device(self) -> str:
        """æ£€æµ‹å¯ç”¨çš„è®¡ç®—è®¾å¤‡ï¼ˆGPUä¼˜å…ˆï¼‰"""
        if torch.cuda.is_available():
            device = 'cuda'
            gpu_name = torch.cuda.get_device_name(0)
            print(f"æ£€æµ‹åˆ°GPU: {gpu_name}ï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿ")
        else:
            device = 'cpu'
            print("æœªæ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CPUå¤„ç†")
        return device
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = self.video_dir / "bgm_replacement.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        self.tmp_dir.mkdir(exist_ok=True)
        self.output_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®Demucsä¸´æ—¶ç›®å½•ç¯å¢ƒå˜é‡
        os.environ['TMPDIR'] = str(self.tmp_dir)
        os.environ['TEMP'] = str(self.tmp_dir)
        os.environ['TMP'] = str(self.tmp_dir)
        
        self.logger.info(f"å·¥ä½œç›®å½•å·²åˆ›å»º: {self.tmp_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•å·²åˆ›å»º: {self.output_dir}")
        self.logger.info(f"Demucsä¸´æ—¶ç›®å½•å·²è®¾ç½®: {self.tmp_dir}")
    
    def get_video_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
        video_files = []
        for ext in self.video_extensions:
            video_files.extend(self.video_dir.glob(f"*{ext}"))
        return sorted(video_files)
    
    def get_bgm_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰BGMæ–‡ä»¶"""
        bgm_files = []
        for ext in self.audio_extensions:
            bgm_files.extend(self.bgm_dir.glob(f"*{ext}"))
        return sorted(bgm_files)
    
    def cleanup_temp_files(self, keep_recent: bool = False):
        """
        æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        Args:
            keep_recent: æ˜¯å¦ä¿ç•™æœ€è¿‘çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        """
        try:
            if not self.tmp_dir.exists():
                return
            
            temp_files = list(self.tmp_dir.glob("*"))
            if not temp_files:
                self.logger.debug("ä¸´æ—¶ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†")
                return
            
            if keep_recent:
                # ä¿ç•™æœ€è¿‘1å°æ—¶å†…åˆ›å»ºçš„æ–‡ä»¶
                import time
                current_time = time.time()
                one_hour_ago = current_time - 3600
                
                for temp_file in temp_files:
                    if temp_file.is_file() and temp_file.stat().st_mtime < one_hour_ago:
                        try:
                            temp_file.unlink()
                            self.logger.debug(f"å·²åˆ é™¤æ—§ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                        except Exception as e:
                            self.logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")
            else:
                # åˆ é™¤æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                for temp_file in temp_files:
                    try:
                        if temp_file.is_file():
                            temp_file.unlink()
                        elif temp_file.is_dir():
                            import shutil
                            shutil.rmtree(temp_file)
                        self.logger.debug(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                    except Exception as e:
                        self.logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")
            
            self.logger.info(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {len(temp_files)} ä¸ªæ–‡ä»¶/ç›®å½•")
            
        except Exception as e:
            self.logger.error(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
    
    def create_looped_bgm(self, bgm_path: Path, target_duration: float) -> Path:
        """åˆ›å»ºå¾ªç¯BGMä»¥åŒ¹é…è§†é¢‘é•¿åº¦"""
        try:
            bgm_clip = AudioFileClip(str(bgm_path))
            bgm_duration = bgm_clip.duration
            
            if bgm_duration >= target_duration:
                # BGMæ¯”è§†é¢‘é•¿ï¼Œç›´æ¥æˆªå–
                looped_bgm = bgm_clip.subclip(0, target_duration)
            else:
                # BGMæ¯”è§†é¢‘çŸ­ï¼Œéœ€è¦å¾ªç¯
                loop_count = int(target_duration / bgm_duration) + 1
                clips = [bgm_clip] * loop_count
                looped_bgm = mp.concatenate_audioclips(clips).subclip(0, target_duration)
            
            # ä¿å­˜å¾ªç¯BGM
            looped_path = self.tmp_dir / f"{bgm_path.stem}_looped.wav"
            looped_bgm.write_audiofile(str(looped_path), verbose=False, logger=None)
            
            bgm_clip.close()
            looped_bgm.close()
            
            return looped_path
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºå¾ªç¯BGMå¤±è´¥: {e}")
            return bgm_path
    
    def _get_codec_params(self) -> Dict[str, Any]:
        """
        è·å–è§†é¢‘ç¼–ç å‚æ•°ï¼Œé’ˆå¯¹ä¸åŒè®¾å¤‡ä¼˜åŒ–
        
        Returns:
            Dict[str, Any]: ç¼–ç å‚æ•°å­—å…¸
        """
        if self.device == 'cuda':
            # GPUåŠ é€Ÿç¼–ç å‚æ•°
            return {
                'codec': 'h264_nvenc',  # NVIDIA GPUç¼–ç å™¨
                'preset': 'fast',       # å¿«é€Ÿé¢„è®¾
                'bitrate': '2000k',     # è¾ƒé«˜æ¯”ç‰¹ç‡ä¿è¯è´¨é‡
                'threads': 1,
                'fps': 24,
                'audio_codec': 'aac',
                'audio_bitrate': '128k'
            }
        else:
            # CPUç¼–ç å‚æ•°
            return {
                'codec': 'libx264',     # CPUç¼–ç å™¨
                'preset': 'medium',     # å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
                'bitrate': '1500k',     # é€‚ä¸­æ¯”ç‰¹ç‡
                'threads': 1,
                'fps': 24,
                'audio_codec': 'aac',
                'audio_bitrate': '128k'
            }
    
    def combine_video_with_new_bgm(self, video_path: Path, separated_audio_path: Path, 
                                 bgm_path: Path) -> bool:
        """
        å°†åˆ†ç¦»çš„éŸ³é¢‘ä¸æ–°BGMåˆæˆ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            separated_audio_path: åˆ†ç¦»åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            bgm_path: æ–°BGMæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åˆæˆæ˜¯å¦æˆåŠŸ
        """
        video_clip = None
        separated_audio = None
        new_bgm = None
        mixed_audio = None
        final_video = None
        looped_bgm_path = None
        
        try:
            self.logger.info(f"ğŸ¬ å¼€å§‹è§†é¢‘åˆæˆ: {video_path.name}")
            self.logger.info(f"ğŸ“ è¾“å…¥æ–‡ä»¶:")
            self.logger.info(f"   - è§†é¢‘: {video_path.name}")
            self.logger.info(f"   - åˆ†ç¦»éŸ³é¢‘: {separated_audio_path.name}")
            self.logger.info(f"   - BGM: {bgm_path.name}")
            
            # åŠ è½½è§†é¢‘ï¼ˆä¸åŒ…å«éŸ³é¢‘ï¼‰
            self.logger.info("ğŸ“¹ åŠ è½½è§†é¢‘æ–‡ä»¶...")
            video_clip = VideoFileClip(str(video_path)).without_audio()
            video_duration = video_clip.duration
            self.logger.info(f"   - è§†é¢‘æ—¶é•¿: {video_duration:.2f}ç§’")
            self.logger.info(f"   - è§†é¢‘åˆ†è¾¨ç‡: {video_clip.size}")
            self.logger.info(f"   - è§†é¢‘å¸§ç‡: {video_clip.fps}")
            
            # åˆ›å»ºå¾ªç¯BGM
            self.logger.info("ğŸµ å¤„ç†BGMéŸ³é¢‘...")
            looped_bgm_path = self.create_looped_bgm(bgm_path, video_duration)
            self.logger.info(f"   - BGMå¾ªç¯æ–‡ä»¶å·²åˆ›å»º: {looped_bgm_path.name}")
            
            # åŠ è½½éŸ³é¢‘
            self.logger.info("ğŸ”Š åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
            separated_audio = AudioFileClip(str(separated_audio_path))
            new_bgm = AudioFileClip(str(looped_bgm_path))
            self.logger.info(f"   - åˆ†ç¦»éŸ³é¢‘æ—¶é•¿: {separated_audio.duration:.2f}ç§’")
            self.logger.info(f"   - BGMéŸ³é¢‘æ—¶é•¿: {new_bgm.duration:.2f}ç§’")
            
            # æ™ºèƒ½éŸ³é¢‘æ··åˆï¼šæ ¹æ®äººå£°å¼ºåº¦åŠ¨æ€è°ƒæ•´BGMéŸ³é‡
            self.logger.info("ğŸ›ï¸ æ™ºèƒ½æ··åˆéŸ³é¢‘...")
            
            # åˆ†æäººå£°å¼ºåº¦ï¼ŒåŠ¨æ€è°ƒæ•´BGMéŸ³é‡
            try:
                separated_audio_array = separated_audio.to_soundarray()
                vocal_rms = np.sqrt(np.mean(separated_audio_array**2))
            except Exception as e:
                self.logger.warning(f"æ— æ³•åˆ†æäººå£°å¼ºåº¦ï¼Œä½¿ç”¨é»˜è®¤BGMéŸ³é‡: {e}")
                vocal_rms = 0.05  # é»˜è®¤ä¸­ç­‰å¼ºåº¦
            
            # ä¼˜åŒ–çš„BGMéŸ³é‡è°ƒæ•´ç®—æ³•ï¼šç¡®ä¿äººå£°æ¸…æ™°çªå‡ºï¼ŒBGMé€‚ä¸­
            # åŸºäºäººå£°å¼ºåº¦çš„æ™ºèƒ½éŸ³é‡è°ƒæ•´ï¼Œäººå£°ä¼˜å…ˆç­–ç•¥
            if vocal_rms > 0.15:  # äººå£°å¾ˆå¼ºï¼ˆå¦‚æ¼”è®²ã€æ­Œå”±ï¼‰
                bgm_volume_factor = 0.12  # BGMå¾ˆè½»ï¼Œå®Œå…¨çªå‡ºäººå£°
                vocal_volume_factor = 1.4  # è¿›ä¸€æ­¥å¢å¼ºå¼ºäººå£°
            elif vocal_rms > 0.08:  # äººå£°è¾ƒå¼ºï¼ˆæ­£å¸¸å¯¹è¯ï¼‰
                bgm_volume_factor = 0.18  # BGMé€‚ä¸­ï¼Œä¿æŒå¹³è¡¡
                vocal_volume_factor = 1.3  # å¢å¼ºæ­£å¸¸å¯¹è¯
            elif vocal_rms > 0.03:  # äººå£°ä¸­ç­‰ï¼ˆè½»å£°å¯¹è¯ï¼‰
                bgm_volume_factor = 0.25  # BGMç¨å¼ºï¼Œè¥é€ æ°›å›´
                vocal_volume_factor = 1.5  # æ˜¾è‘—å¢å¼ºè½»å£°å¯¹è¯
            else:  # äººå£°è¾ƒå¼±æˆ–æ— äººå£°æ®µè½
                bgm_volume_factor = 0.35  # BGMè¾ƒå¼ºï¼Œå¡«å……ç©ºç™½
                vocal_volume_factor = 1.6  # å¤§å¹…å¢å¼ºå¾®å¼±äººå£°
                
            self.logger.info(f"   - äººå£°RMSå¼ºåº¦: {vocal_rms:.4f}")
            self.logger.info(f"   - åˆ†ç¦»éŸ³é¢‘éŸ³é‡: {vocal_volume_factor} (äººå£°å¢å¼º)")
            self.logger.info(f"   - BGMéŸ³é‡: {bgm_volume_factor}")
            
            # è®¡ç®—æ€»éŸ³é‡å› å­ï¼ˆåœ¨æ··åˆåè®¡ç®—ï¼‰
            if vocal_volume_factor >= 1.5:
                total_volume_factor = 0.75
            elif vocal_volume_factor >= 1.3:
                total_volume_factor = 0.80
            else:
                total_volume_factor = 0.85
            
            self.logger.info(f"   - æ€»éŸ³é‡è°ƒæ•´: {total_volume_factor} (é˜²æ­¢å‰Šæ³¢)")
            
            # åº”ç”¨ä¼˜åŒ–çš„æ™ºèƒ½éŸ³é¢‘æ··åˆ
            mixed_audio = mp.CompositeAudioClip([
                separated_audio.volumex(vocal_volume_factor),  # æ ¹æ®äººå£°å¼ºåº¦è°ƒæ•´åˆ†ç¦»éŸ³é¢‘éŸ³é‡
                new_bgm.volumex(bgm_volume_factor)  # åŠ¨æ€è°ƒæ•´BGMéŸ³é‡
            ])
            
            # æ™ºèƒ½éŸ³é¢‘æ ‡å‡†åŒ–ï¼šæ ¹æ®æ··åˆåçš„éŸ³é¢‘ç‰¹æ€§è°ƒæ•´æ€»éŸ³é‡
            # è€ƒè™‘åˆ°äººå£°å¢å¼ºï¼Œé€‚å½“é™ä½æ€»éŸ³é‡é¿å…å‰Šæ³¢ï¼ŒåŒæ—¶ä¿æŒæ¸…æ™°åº¦
            mixed_audio = mixed_audio.volumex(total_volume_factor)  # åŠ¨æ€è°ƒæ•´æ€»éŸ³é‡
            
            # åˆæˆæœ€ç»ˆè§†é¢‘
            self.logger.info("ğŸï¸ åˆæˆæœ€ç»ˆè§†é¢‘...")
            final_video = video_clip.set_audio(mixed_audio)
            
            # è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_path = self.output_dir / f"{video_path.stem}_with_new_bgm.mp4"
            self.logger.info(f"ğŸ“¤ è¾“å‡ºè·¯å¾„: {output_path}")
            
            # è·å–ç¼–ç å‚æ•°ï¼ˆé’ˆå¯¹GPUä¼˜åŒ–ï¼‰
            codec_params = self._get_codec_params()
            self.logger.info(f"âš™ï¸ ç¼–ç å‚æ•°: {codec_params}")
            
            # å¦‚æœæœ‰GPUï¼Œä½¿ç”¨GPUåŠ é€Ÿç¼–ç 
            if self.device == 'cuda':
                self.logger.info("ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿè§†é¢‘ç¼–ç ...")
                # ä¸ºGPUä¼˜åŒ–ç¼–ç å‚æ•°
                codec_params.update({
                    'codec': 'h264_nvenc',  # ä½¿ç”¨NVIDIA GPUç¼–ç å™¨
                    'preset': 'fast',
                    'bitrate': '2000k'
                })
                self.logger.info(f"   - GPUç¼–ç å™¨: h264_nvenc")
            else:
                self.logger.info("ğŸ’» ä½¿ç”¨CPUè¿›è¡Œè§†é¢‘ç¼–ç ...")
            
            # å†™å…¥è§†é¢‘æ–‡ä»¶
            self.logger.info("ğŸ’¾ å¼€å§‹å†™å…¥è§†é¢‘æ–‡ä»¶...")
            start_time = time.time()
            
            final_video.write_videofile(
                str(output_path),
                verbose=False,
                logger=None,
                **codec_params
            )
            
            encode_time = time.time() - start_time
            self.logger.info(f"âœ… è§†é¢‘ç¼–ç å®Œæˆï¼Œè€—æ—¶: {encode_time:.2f}ç§’")
            
            # è·å–è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            if output_path.exists():
                file_size = output_path.stat().st_size / (1024 * 1024)  # MB
                self.logger.info(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶ä¿¡æ¯:")
                self.logger.info(f"   - æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                self.logger.info(f"   - æ–‡ä»¶è·¯å¾„: {output_path}")
            
            self.logger.info(f"ğŸ‰ è§†é¢‘åˆæˆå®Œæˆ: {output_path.name}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è§†é¢‘åˆæˆå¤±è´¥ {video_path.name}: {e}")
            self.logger.error(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - é”™è¯¯è¯¦æƒ…: {str(e)}")
            return False
        finally:
            # èµ„æºæ¸…ç†
            self.logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
            clips = [video_clip, separated_audio, new_bgm, mixed_audio, final_video]
            for i, clip in enumerate(clips):
                if clip:
                    try:
                        clip.close()
                        self.logger.debug(f"   - å·²é‡Šæ”¾èµ„æº {i+1}/5")
                    except Exception as cleanup_error:
                        self.logger.warning(f"   - èµ„æºé‡Šæ”¾è­¦å‘Š: {cleanup_error}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if looped_bgm_path and looped_bgm_path.exists():
                try:
                    time.sleep(1.0)
                    looped_bgm_path.unlink()
                    self.logger.info(f"   - å·²åˆ é™¤ä¸´æ—¶BGMæ–‡ä»¶: {looped_bgm_path.name}")
                except Exception as cleanup_error:
                    self.logger.warning(f"   - æ¸…ç†å¾ªç¯BGMæ–‡ä»¶å¤±è´¥: {cleanup_error}")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶å’ŒGPUå†…å­˜æ¸…ç†
            gc.collect()
            if self.device == 'cuda':
                torch.cuda.empty_cache()
                self.logger.info("   - GPUå†…å­˜å·²æ¸…ç†")
            self.logger.info("âœ¨ èµ„æºæ¸…ç†å®Œæˆ")
    
    def process_single_video(self, video_path: Path, bgm_files: List[Path]) -> bool:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            bgm_files: BGMæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        separated_audio_path = None
        try:
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ¯ å¼€å§‹å¤„ç†è§†é¢‘: {video_path.name}")
            self.logger.info(f"ğŸ“‚ æ–‡ä»¶è·¯å¾„: {video_path}")
            
            # éšæœºé€‰æ‹©BGM
            selected_bgm = random.choice(bgm_files)
            self.logger.info(f"ğŸµ ä¸º {video_path.name} é€‰æ‹©BGM: {selected_bgm.name}")
            self.logger.info(f"ğŸ“‚ BGMè·¯å¾„: {selected_bgm}")
            
            # æå–è§†é¢‘éŸ³é¢‘
            self.logger.info("ğŸ¬ æå–è§†é¢‘éŸ³é¢‘...")
            video_clip = VideoFileClip(str(video_path))
            if video_clip.audio is None:
                self.logger.warning(f"âš ï¸ è§†é¢‘æ–‡ä»¶æ²¡æœ‰éŸ³é¢‘è½¨é“: {video_path.name}")
                video_clip.close()
                return False
            
            self.logger.info(f"   - è§†é¢‘æ—¶é•¿: {video_clip.duration:.2f}ç§’")
            self.logger.info(f"   - éŸ³é¢‘é‡‡æ ·ç‡: {video_clip.audio.fps}Hz")
            
            audio_path = self.tmp_dir / f"{video_path.stem}_original.wav"
            self.logger.info(f"ğŸ’¾ ä¿å­˜åŸå§‹éŸ³é¢‘åˆ°: {audio_path.name}")
            
            video_clip.audio.write_audiofile(str(audio_path), verbose=False, logger=None)
            video_clip.close()
            
            # ä½¿ç”¨é«˜çº§åˆ†ç¦»å™¨åˆ†ç¦»éŸ³é¢‘
            self.logger.info("ğŸ”§ å¼€å§‹éŸ³é¢‘åˆ†ç¦»...")
            self.logger.info(f"   - åˆ†ç¦»ç­–ç•¥: {self.separation_config.strategy.value}")
            self.logger.info(f"   - ä½¿ç”¨æ¨¡å‹: {self.separation_config.model_name}")
            self.logger.info(f"   - è®¡ç®—è®¾å¤‡: {self.device}")
            
            separated_audio_path, quality_metrics = self.audio_separator.separate_audio(audio_path, self.tmp_dir)
            
            if not separated_audio_path:
                self.logger.error("âŒ éŸ³é¢‘åˆ†ç¦»å¤±è´¥")
                return False
            
            self.logger.info(f"âœ… éŸ³é¢‘åˆ†ç¦»å®Œæˆ: {separated_audio_path.name}")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            if quality_metrics:
                self.stats['avg_quality_score'] += quality_metrics.quality_score
                self.logger.info(f"ğŸ“Š åˆ†ç¦»è´¨é‡è¯„ä¼°:")
                self.logger.info(f"   - è´¨é‡åˆ†æ•°: {quality_metrics.quality_score:.3f}")
                self.logger.info(f"   - ä¿¡å™ªæ¯”: {quality_metrics.snr:.2f} dB")
                self.logger.info(f"   - é¢‘è°±è´¨å¿ƒ: {quality_metrics.spectral_centroid:.2f} Hz")
                self.logger.info(f"   - RMSèƒ½é‡: {quality_metrics.rms_energy:.4f}")
            
            # åˆæˆæ–°è§†é¢‘
            self.logger.info("ğŸï¸ å¼€å§‹è§†é¢‘åˆæˆ...")
            success = self.combine_video_with_new_bgm(video_path, separated_audio_path, selected_bgm)
            
            # æ¸…ç†åŸå§‹éŸ³é¢‘æ–‡ä»¶
            if audio_path.exists():
                audio_path.unlink()
                self.logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†åŸå§‹éŸ³é¢‘æ–‡ä»¶: {audio_path.name}")
            
            if success:
                self.logger.info(f"ğŸ‰ è§†é¢‘å¤„ç†æˆåŠŸ: {video_path.name}")
            else:
                self.logger.error(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {video_path.name}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†è§†é¢‘å¼‚å¸¸ {video_path.name}: {e}")
            self.logger.error(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - é”™è¯¯è¯¦æƒ…: {str(e)}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if separated_audio_path and separated_audio_path.exists():
                try:
                    time.sleep(1.0)
                    separated_audio_path.unlink()
                    self.logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†åˆ†ç¦»éŸ³é¢‘æ–‡ä»¶: {separated_audio_path.name}")
                except Exception as cleanup_error:
                    self.logger.warning(f"âš ï¸ æ¸…ç†åˆ†ç¦»éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {cleanup_error}")
            
            self.logger.info("=" * 60)
    
    def process_videos_with_batch_separation(self, video_files: List[Path], bgm_files: List[Path]) -> bool:
        """
        ä½¿ç”¨video_separatorçš„æ‰¹é‡åˆ†ç¦»åŠŸèƒ½å¤„ç†è§†é¢‘
        
        Args:
            video_files: è§†é¢‘æ–‡ä»¶åˆ—è¡¨
            bgm_files: BGMæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            self.logger.info("ğŸ”§ ä½¿ç”¨æ‰¹é‡åˆ†ç¦»æ¨¡å¼å¤„ç†è§†é¢‘...")
            
            # åˆ›å»ºä¸´æ—¶åˆ†ç¦»ç›®å½•
            batch_separation_dir = self.tmp_dir / "batch_separated"
            batch_separation_dir.mkdir(exist_ok=True)
            
            # ä½¿ç”¨video_separatorè¿›è¡Œæ‰¹é‡åˆ†ç¦»
            self.logger.info(f"ğŸ“‚ æ‰¹é‡åˆ†ç¦»è¾“å…¥ç›®å½•: {self.video_dir}")
            self.logger.info(f"ğŸ“‚ æ‰¹é‡åˆ†ç¦»è¾“å‡ºç›®å½•: {batch_separation_dir}")
            
            # è°ƒç”¨batch_separate_videoså‡½æ•°
            separation_results = self.video_separator.batch_separate_videos(
                input_dir=str(self.video_dir),
                output_dir=str(batch_separation_dir),
                max_workers=self.separation_config.batch_max_workers,
                extract_silent=False,  # æˆ‘ä»¬ä¸éœ€è¦æ— å£°è§†é¢‘
                separate_audio=True    # éœ€è¦åˆ†ç¦»éŸ³é¢‘
            )
            
            self.logger.info(f"âœ… æ‰¹é‡åˆ†ç¦»å®Œæˆï¼ŒæˆåŠŸå¤„ç† {separation_results['successful']} ä¸ªæ–‡ä»¶")
            
            if separation_results['failed'] > 0:
                self.logger.warning(f"âš ï¸ {separation_results['failed']} ä¸ªæ–‡ä»¶åˆ†ç¦»å¤±è´¥")
            
            # å¤„ç†åˆ†ç¦»åçš„éŸ³é¢‘æ–‡ä»¶ï¼Œä¸BGMåˆæˆ
            success_count = 0
            for video_file in video_files:
                try:
                    # æŸ¥æ‰¾å¯¹åº”çš„åˆ†ç¦»éŸ³é¢‘æ–‡ä»¶
                    separated_audio_dir = batch_separation_dir / video_file.stem
                    vocals_file = separated_audio_dir / "vocals.wav"
                    other_file = separated_audio_dir / "other.wav"
                    
                    if not vocals_file.exists():
                        self.logger.error(f"âŒ æœªæ‰¾åˆ°åˆ†ç¦»çš„äººå£°æ–‡ä»¶: {vocals_file}")
                        continue
                    
                    # æ ¹æ®åˆ†ç¦»ç­–ç•¥åˆæˆéŸ³é¢‘
                    combined_audio_path = self._combine_separated_audio(
                        vocals_file, other_file, video_file.stem
                    )
                    
                    if combined_audio_path:
                        # éšæœºé€‰æ‹©BGMå¹¶åˆæˆè§†é¢‘
                        selected_bgm = random.choice(bgm_files)
                        self.logger.info(f"ğŸµ ä¸º {video_file.name} é€‰æ‹©BGM: {selected_bgm.name}")
                        
                        if self.combine_video_with_new_bgm(video_file, combined_audio_path, selected_bgm):
                            success_count += 1
                            self.logger.info(f"âœ… è§†é¢‘å¤„ç†æˆåŠŸ: {video_file.name}")
                        else:
                            self.logger.error(f"âŒ è§†é¢‘åˆæˆå¤±è´¥: {video_file.name}")
                    
                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†è§†é¢‘å¼‚å¸¸ {video_file.name}: {e}")
            
            # æ¸…ç†ä¸´æ—¶åˆ†ç¦»æ–‡ä»¶
            try:
                import shutil
                shutil.rmtree(batch_separation_dir)
                self.logger.info("ğŸ—‘ï¸ å·²æ¸…ç†æ‰¹é‡åˆ†ç¦»ä¸´æ—¶æ–‡ä»¶")
            except Exception as cleanup_error:
                self.logger.warning(f"âš ï¸ æ¸…ç†æ‰¹é‡åˆ†ç¦»ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")
            
            self.stats['successful_videos'] = success_count
            self.stats['failed_videos'] = len(video_files) - success_count
            
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡åˆ†ç¦»å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    def _combine_separated_audio(self, vocals_file: Path, other_file: Path, video_stem: str) -> Optional[Path]:
        """
        æ ¹æ®åˆ†ç¦»ç­–ç•¥åˆæˆåˆ†ç¦»åçš„éŸ³é¢‘
        
        Args:
            vocals_file: äººå£°æ–‡ä»¶è·¯å¾„
            other_file: å…¶ä»–éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            video_stem: è§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            åˆæˆåçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            vocals_audio, sr = librosa.load(str(vocals_file), sr=None)
            
            # æ ¹æ®ç­–ç•¥å¤„ç†
            if self.separation_config.strategy == SeparationStrategy.VOCALS_ONLY:
                # åªä¿ç•™äººå£°
                combined_audio = vocals_audio * self.separation_config.vocals_volume
            elif self.separation_config.strategy == SeparationStrategy.VOCALS_AND_OTHER:
                # ä¿ç•™äººå£°å’Œå…¶ä»–éŸ³é¢‘
                if other_file.exists():
                    other_audio, _ = librosa.load(str(other_file), sr=sr)
                    # ç¡®ä¿éŸ³é¢‘é•¿åº¦ä¸€è‡´
                    min_length = min(len(vocals_audio), len(other_audio))
                    vocals_audio = vocals_audio[:min_length]
                    other_audio = other_audio[:min_length]
                    
                    combined_audio = (vocals_audio * self.separation_config.vocals_volume + 
                                    other_audio * self.separation_config.other_volume)
                else:
                    combined_audio = vocals_audio * self.separation_config.vocals_volume
            else:
                # é»˜è®¤åªä¿ç•™äººå£°
                combined_audio = vocals_audio * self.separation_config.vocals_volume
            
            # ä¿å­˜åˆæˆéŸ³é¢‘
            output_path = self.tmp_dir / f"{video_stem}_combined.wav"
            sf.write(str(output_path), combined_audio, sr)
            
            self.logger.info(f"âœ… éŸ³é¢‘åˆæˆå®Œæˆ: {output_path.name}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘åˆæˆå¤±è´¥: {e}")
            return None
    
    def process_videos(self):
        """æ‰¹é‡å¤„ç†è§†é¢‘æ–‡ä»¶"""
        self.logger.info("ğŸš€ å¯åŠ¨è§†é¢‘BGMæ›¿æ¢å·¥å…· v3.0")
        self.logger.info("=" * 80)
        
        video_files = self.get_video_files()
        bgm_files = self.get_bgm_files()
        
        if not video_files:
            self.logger.error("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            self.logger.error(f"   - æœç´¢ç›®å½•: {self.video_dir}")
            self.logger.error(f"   - æ”¯æŒæ ¼å¼: {', '.join(self.video_extensions)}")
            return
        
        if not bgm_files:
            self.logger.error("âŒ æœªæ‰¾åˆ°BGMæ–‡ä»¶")
            self.logger.error(f"   - æœç´¢ç›®å½•: {self.bgm_dir}")
            self.logger.error(f"   - æ”¯æŒæ ¼å¼: {', '.join(self.audio_extensions)}")
            return
        
        self.stats['total_videos'] = len(video_files)
        
        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        self.logger.info("ğŸ“‹ å¤„ç†é…ç½®:")
        self.logger.info(f"   - è§†é¢‘æ–‡ä»¶æ•°é‡: {len(video_files)}")
        self.logger.info(f"   - BGMæ–‡ä»¶æ•°é‡: {len(bgm_files)}")
        self.logger.info(f"   - åˆ†ç¦»ç­–ç•¥: {self.separation_config.strategy.value}")
        self.logger.info(f"   - ä½¿ç”¨æ¨¡å‹: {self.separation_config.model_name}")
        self.logger.info(f"   - æ¨¡å‹é‡å ç‡: {self.separation_config.overlap}")
        self.logger.info(f"   - è®¡ç®—è®¾å¤‡: {self.device}")
        self.logger.info(f"   - å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        self.logger.info(f"   - è´¨é‡é˜ˆå€¼: {self.separation_config.quality_threshold}")
        self.logger.info(f"   - é¢„å¤„ç†: {'å¯ç”¨' if self.separation_config.enable_preprocessing else 'ç¦ç”¨'}")
        self.logger.info(f"   - è´¨é‡æ£€æŸ¥: {'å¯ç”¨' if self.separation_config.enable_quality_check else 'ç¦ç”¨'}")
        
        # æ˜¾ç¤ºç›®å½•ä¿¡æ¯
        self.logger.info("ğŸ“ ç›®å½•ä¿¡æ¯:")
        self.logger.info(f"   - è§†é¢‘ç›®å½•: {self.video_dir}")
        self.logger.info(f"   - BGMç›®å½•: {self.bgm_dir}")
        self.logger.info(f"   - ä¸´æ—¶ç›®å½•: {self.tmp_dir}")
        self.logger.info(f"   - è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        self.logger.info("ğŸ“„ è§†é¢‘æ–‡ä»¶åˆ—è¡¨:")
        for i, video_file in enumerate(video_files, 1):
            file_size = video_file.stat().st_size / (1024 * 1024)  # MB
            self.logger.info(f"   {i:2d}. {video_file.name} ({file_size:.1f} MB)")
        
        self.logger.info("ğŸµ BGMæ–‡ä»¶åˆ—è¡¨:")
        for i, bgm_file in enumerate(bgm_files, 1):
            file_size = bgm_file.stat().st_size / (1024 * 1024)  # MB
            self.logger.info(f"   {i:2d}. {bgm_file.name} ({file_size:.1f} MB)")
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç†...")
        
        start_time = time.time()
        
        # æ ¹æ®é…ç½®é€‰æ‹©å¤„ç†æ¨¡å¼
        if self.separation_config.use_batch_separation and self.video_separator:
            self.logger.info("ğŸ”§ ä½¿ç”¨æ‰¹é‡åˆ†ç¦»æ¨¡å¼")
            success = self.process_videos_with_batch_separation(video_files, bgm_files)
            
            if not success:
                self.logger.error("âŒ æ‰¹é‡åˆ†ç¦»æ¨¡å¼å¤„ç†å¤±è´¥")
                return
        else:
            self.logger.info("ğŸ”§ ä½¿ç”¨ä¼ ç»Ÿåˆ†ç¦»æ¨¡å¼")
            
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                self.logger.info(f"ğŸ”§ åˆ›å»ºçº¿ç¨‹æ± ï¼Œæœ€å¤§å¹¶å‘æ•°: {self.max_workers}")
                
                # æäº¤ä»»åŠ¡
                future_to_video = {
                    executor.submit(self.process_single_video, video_file, bgm_files): video_file
                    for video_file in video_files
                }
                
                self.logger.info(f"ğŸ“¤ å·²æäº¤ {len(future_to_video)} ä¸ªå¤„ç†ä»»åŠ¡")
                
                # å¤„ç†ç»“æœ
                completed_count = 0
                for future in as_completed(future_to_video):
                    video_file = future_to_video[future]
                    completed_count += 1
                    
                    try:
                        success = future.result()
                        if success:
                            self.stats['successful'] += 1
                            self.logger.info(f"âœ… [{completed_count}/{len(video_files)}] æˆåŠŸå¤„ç†: {video_file.name}")
                        else:
                            self.stats['failed'] += 1
                            self.logger.error(f"âŒ [{completed_count}/{len(video_files)}] å¤„ç†å¤±è´¥: {video_file.name}")
                    except Exception as e:
                        self.stats['failed'] += 1
                        self.logger.error(f"âŒ [{completed_count}/{len(video_files)}] å¤„ç†å¼‚å¸¸ {video_file.name}: {e}")
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (completed_count / len(video_files)) * 100
                    self.logger.info(f"ğŸ“Š å¤„ç†è¿›åº¦: {progress:.1f}% ({completed_count}/{len(video_files)})")
        
        # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
        if self.stats['successful'] > 0:
            self.stats['avg_quality_score'] /= self.stats['successful']
        
        end_time = time.time()
        duration = end_time - start_time
        
        # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡æŠ¥å‘Š:")
        self.logger.info("=" * 80)
        self.logger.info(f"ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        self.logger.info(f"   - æ€»è§†é¢‘æ•°: {self.stats['total_videos']}")
        self.logger.info(f"   - æˆåŠŸå¤„ç†: {self.stats['successful']}")
        self.logger.info(f"   - å¤„ç†å¤±è´¥: {self.stats['failed']}")
        self.logger.info(f"   - æˆåŠŸç‡: {self.stats['successful']/self.stats['total_videos']*100:.1f}%")
        
        self.logger.info(f"ğŸ¯ è´¨é‡ç»Ÿè®¡:")
        self.logger.info(f"   - å¹³å‡è´¨é‡åˆ†æ•°: {self.stats['avg_quality_score']:.3f}")
        
        self.logger.info(f"â±ï¸ æ€§èƒ½ç»Ÿè®¡:")
        self.logger.info(f"   - æ€»è€—æ—¶: {duration:.1f} ç§’")
        self.logger.info(f"   - å¹³å‡æ¯ä¸ªè§†é¢‘: {duration/self.stats['total_videos']:.1f} ç§’")
        if self.stats['successful'] > 0:
            self.logger.info(f"   - æˆåŠŸè§†é¢‘å¹³å‡è€—æ—¶: {duration/self.stats['successful']:.1f} ç§’")
        
        self.logger.info(f"ğŸ“ è¾“å‡ºä¿¡æ¯:")
        self.logger.info(f"   - è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # è®¡ç®—è¾“å‡ºæ–‡ä»¶æ€»å¤§å°
        total_output_size = 0
        output_files = list(self.output_dir.glob("*.mp4"))
        for output_file in output_files:
            total_output_size += output_file.stat().st_size
        
        if total_output_size > 0:
            total_output_size_mb = total_output_size / (1024 * 1024)
            self.logger.info(f"   - è¾“å‡ºæ–‡ä»¶æ•°: {len(output_files)}")
            self.logger.info(f"   - æ€»è¾“å‡ºå¤§å°: {total_output_size_mb:.1f} MB")
            self.logger.info(f"   - å¹³å‡æ–‡ä»¶å¤§å°: {total_output_size_mb/len(output_files):.1f} MB")
        
        self.logger.info(f"ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:")
        self.logger.info(f"   - ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.logger.info(f"   - å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        
        if self.device == 'cuda':
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            self.logger.info(f"   - GPUå†…å­˜: {gpu_memory:.1f} GB")
        
        self.logger.info("=" * 80)
        
        # å…¨å±€ä¸´æ—¶æ–‡ä»¶æ¸…ç†
        self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        self.cleanup_temp_files(keep_recent=False)
        
        if self.stats['successful'] == self.stats['total_videos']:
            self.logger.info("ğŸ‰ æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼")
        elif self.stats['successful'] > 0:
            self.logger.info(f"âš ï¸ éƒ¨åˆ†è§†é¢‘å¤„ç†å®Œæˆï¼Œ{self.stats['failed']} ä¸ªè§†é¢‘å¤„ç†å¤±è´¥")
        else:
            self.logger.error("âŒ æ‰€æœ‰è§†é¢‘å¤„ç†å¤±è´¥")
        
        self.logger.info("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è§†é¢‘BGMåˆ†ç¦»å’Œæ›¿æ¢å·¥å…· v3.0')
    parser.add_argument('video_dir', help='è§†é¢‘æ–‡ä»¶ç›®å½•')
    parser.add_argument('bgm_dir', help='BGMéŸ³é¢‘æ–‡ä»¶ç›®å½•')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 4)')
    parser.add_argument('--strategy', choices=['vocals_only', 'vocals_and_other', 'custom_mix', 'adaptive'],
                       default='vocals_and_other', help='åˆ†ç¦»ç­–ç•¥ (é»˜è®¤: vocals_and_other - ä¿ç•™äººå£°å’Œç¯å¢ƒéŸ³ï¼Œå»é™¤BGM)')
    parser.add_argument('--model', default='htdemucs', help='demucsæ¨¡å‹åç§° (é»˜è®¤: htdemucs)')
    parser.add_argument('--overlap', type=float, default=0.25, help='æ¨¡å‹é‡å å‚æ•° (é»˜è®¤: 0.25)')
    parser.add_argument('--vocals-volume', type=float, default=2.0, help='äººå£°éŸ³é‡ (é»˜è®¤: 2.0ï¼Œå¢å¼º30%%)')
    parser.add_argument('--other-volume', type=float, default=0.15, help='å…¶ä»–éŸ³é¢‘éŸ³é‡ (é»˜è®¤: 0.15 - ç¯å¢ƒéŸ³ä¸æ–°BGMå¹³è¡¡)')
    parser.add_argument('--quality-threshold', type=float, default=0.7, help='è´¨é‡é˜ˆå€¼ (é»˜è®¤: 0.7)')
    parser.add_argument('--disable-preprocessing', action='store_true', help='ç¦ç”¨éŸ³é¢‘é¢„å¤„ç†')
    parser.add_argument('--disable-quality-check', action='store_true', help='ç¦ç”¨è´¨é‡æ£€æŸ¥')
    parser.add_argument('--use-batch-separation', action='store_true', help='ä½¿ç”¨video_separatorçš„æ‰¹é‡åˆ†ç¦»åŠŸèƒ½')
    parser.add_argument('--batch-workers', type=int, default=2, help='æ‰¹é‡åˆ†ç¦»çš„æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 2)')
    
    args = parser.parse_args()
    
    # å…¨å±€å˜é‡ç”¨äºä¿¡å·å¤„ç†
    global_replacer = None
    
    def cleanup_on_exit():
        """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°"""
        if global_replacer:
            try:
                print("ğŸ§¹ ç¨‹åºé€€å‡ºï¼Œæ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
                global_replacer.cleanup_temp_files(keep_recent=False)
            except Exception as e:
                print(f"âš ï¸ é€€å‡ºæ—¶ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
    
    def signal_handler(signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        print(f"\nâš ï¸ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨æ¸…ç†å¹¶é€€å‡º...")
        cleanup_on_exit()
        sys.exit(1)
    
    # # æ³¨å†Œä¿¡å·å¤„ç†å™¨å’Œé€€å‡ºå¤„ç†å™¨
    # signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
    # if hasattr(signal, 'SIGTERM'):
    #     signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·
    # atexit.register(cleanup_on_exit)
    
    # éªŒè¯ç›®å½•
    if not os.path.exists(args.video_dir):
        print(f"é”™è¯¯: è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {args.video_dir}")
        sys.exit(1)
    
    if not os.path.exists(args.bgm_dir):
        print(f"é”™è¯¯: BGMç›®å½•ä¸å­˜åœ¨: {args.bgm_dir}")
        sys.exit(1)
    
    # åˆ›å»ºåˆ†ç¦»é…ç½®
    separation_config = SeparationConfig(
        strategy=SeparationStrategy(args.strategy),
        model_name=args.model,
        overlap=args.overlap,
        vocals_volume=args.vocals_volume,
        other_volume=args.other_volume,
        quality_threshold=args.quality_threshold,
        enable_preprocessing=not args.disable_preprocessing,
        enable_quality_check=not args.disable_quality_check,
        use_batch_separation=args.use_batch_separation,
        batch_max_workers=args.batch_workers
    )
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶å¼€å§‹å¤„ç†
    try:
        global_replacer = VideoBGMReplacer(args.video_dir, args.bgm_dir, args.workers, separation_config)
        global_replacer.process_videos()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        if global_replacer:
            print("ğŸ§¹ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            global_replacer.cleanup_temp_files(keep_recent=False)
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {e}")
        if global_replacer:
            print("ğŸ§¹ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            global_replacer.cleanup_temp_files(keep_recent=False)
        sys.exit(1)
    finally:
        # ç¡®ä¿åœ¨ç¨‹åºç»“æŸæ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if global_replacer:
            try:
                global_replacer.cleanup_temp_files(keep_recent=False)
            except Exception as cleanup_error:
                print(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {cleanup_error}")


if __name__ == "__main__":
    main()